{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fc74d4-d9b1-43d3-9f1c-461d9fead8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Load the dataset\n",
    "file_path = (r\"C:\\Users\\nidhi\\Documents\\Spring_Semester\\Dissertation\\Kaggle-chronic kidney disease prediction\\Chronic_Kidney_Dsease_data_Cleaned.csv\")\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e33d88-b885-45aa-9e7b-ebb528581419",
   "metadata": {},
   "source": [
    "# version 8 of LIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22623b48-e644-4e41-8f8e-5f94259c8ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from lit_nlp import dev_server\n",
    "from lit_nlp import server_flags\n",
    "from lit_nlp.api import layout\n",
    "from lit_nlp.components import minimal_targeted_counterfactuals\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "\n",
    "# Paths to your model and dataset\n",
    "MODEL_PATH = r\"C:\\Users\\nidhi\\Documents\\Spring_Semester\\Dissertation\\best_rf_model.pkl\"\n",
    "DATA_PATH = r\"C:\\Users\\nidhi\\Documents\\Spring_Semester\\Dissertation\\Kaggle-chronic kidney disease prediction\\Chronic_Kidney_Dsease_data_Cleaned.csv\"\n",
    "\n",
    "# List of 30 features used in your model\n",
    "FEATURE_COLUMNS = [\n",
    "    'SerumCreatinine', 'Itching', 'FastingBloodSugar', 'MuscleCramps',\n",
    "    'BUNLevels', 'ProteinInUrine', 'SystolicBP', 'HbA1c', 'BMI', 'FamilyHistoryKidneyDisease',\n",
    "    'Edema', 'CholesterolHDL', 'HemoglobinLevels', 'Gender', 'QualityOfLifeScore', 'CholesterolLDL', 'Statins', 'CholesterolTriglycerides',\n",
    "    'SerumElectrolytesPhosphorus', 'AntidiabeticMedications',\n",
    "    'OccupationalExposureChemicals', 'WaterQuality', 'NauseaVomiting',\n",
    "    'PhysicalActivity', 'SocioeconomicStatus', 'EducationLevel',\n",
    "    'CholesterolTotal', 'DietQuality', 'PatientID', 'GFR'\n",
    "]\n",
    "\n",
    "# Function to load your model\n",
    "def load_model(model_path):\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# Function to load your dataset\n",
    "def load_dataset(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[FEATURE_COLUMNS + ['Diagnosis']]  # Select only the 30 features plus the label column\n",
    "    print(\"Dataset loaded with shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# Wrapper for scikit-learn model to make it compatible with LIT\n",
    "class SklearnModelWrapper(lit_model.Model):\n",
    "    def __init__(self, model: ClassifierMixin):\n",
    "        self.model = model\n",
    "        self.class_names = list(model.classes_)\n",
    "\n",
    "    def predict_minibatch(self, inputs):\n",
    "        \"\"\"Predict on a batch of inputs.\"\"\"\n",
    "        input_data = np.array([ex['input'] for ex in inputs])\n",
    "        probabilities = self.model.predict_proba(input_data)\n",
    "        predicted_classes = self.model.predict(input_data)\n",
    "        return [{\n",
    "            'predictions': pred,\n",
    "            'probabilities': probs.tolist()\n",
    "        } for pred, probs in zip(predicted_classes, probabilities)]\n",
    "\n",
    "    def input_spec(self):\n",
    "        return {\n",
    "            'input': lit_types.Embeddings()\n",
    "        }\n",
    "\n",
    "    def output_spec(self):\n",
    "        return {\n",
    "            'predictions': lit_types.CategoryLabel(vocab=self.class_names),\n",
    "            'probabilities': lit_types.MulticlassPreds(vocab=self.class_names),\n",
    "        }\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        return self.predict_minibatch(inputs)\n",
    "\n",
    "# Wrapper for the dataset to make it compatible with LIT\n",
    "class CustomDataset(lit_dataset.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self._examples = [{\n",
    "            'input': row[:-1].values.tolist(),  \n",
    "            'label': row[-1]\n",
    "        } for _, row in dataframe.iterrows()]\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            'input': lit_types.Embeddings(),\n",
    "            'label': lit_types.CategoryLabel(),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._examples[idx]\n",
    "\n",
    "# Custom frontend layout; see api/layout.py\n",
    "modules = layout.LitModuleName\n",
    "CUSTOM_LAYOUT = layout.LitCanonicalLayout(\n",
    "    upper={\n",
    "        'Main': [\n",
    "            modules.DiveModule,\n",
    "            modules.DataTableModule,\n",
    "            modules.DatapointEditorModule,\n",
    "        ]\n",
    "    },\n",
    "    lower=layout.STANDARD_LAYOUT.lower,\n",
    "    description='Custom layout for your demo.',\n",
    ")\n",
    "CUSTOM_LAYOUTS = layout.DEFAULT_LAYOUTS | {'custom_layout': CUSTOM_LAYOUT}\n",
    "\n",
    "# Try to define the port flag, catch the DuplicateFlagError if it is already defined\n",
    "try:\n",
    "    flags.DEFINE_integer('port', 6006, 'Port to run the LIT server on.')\n",
    "except flags.DuplicateFlagError:\n",
    "    pass\n",
    "\n",
    "def run_lit(argv):\n",
    "    # Load custom model and dataset\n",
    "    model = load_model(MODEL_PATH)\n",
    "    dataframe = load_dataset(DATA_PATH)\n",
    "\n",
    "    # Wrap the model with SklearnModelWrapper\n",
    "    lit_model = SklearnModelWrapper(model)\n",
    "\n",
    "    # Wrap the dataframe with CustomDataset\n",
    "    dataset = CustomDataset(dataframe)\n",
    "\n",
    "    models = {'custom_classifier': lit_model}\n",
    "    datasets = {'custom_dataset': dataset}\n",
    "\n",
    "    # Truncate datasets if --max_examples is set.\n",
    "    max_examples = 1660  # or any other number you want to set as a limit\n",
    "    if max_examples is not None:\n",
    "        for name in datasets:\n",
    "            logging.info(\"Dataset: '%s' with %d examples\", name, len(datasets[name]))\n",
    "            datasets[name]._examples = datasets[name]._examples[:max_examples]\n",
    "            logging.info('  truncated to %d examples', len(datasets[name]))\n",
    "\n",
    "    generators = {\n",
    "        'Minimal Targeted Counterfactuals': minimal_targeted_counterfactuals.TabularMTC()\n",
    "    }\n",
    "\n",
    "    lit_demo = dev_server.Server(\n",
    "        models,\n",
    "        datasets,\n",
    "        generators=generators,\n",
    "        layouts=CUSTOM_LAYOUTS,\n",
    "        **server_flags.get_flags())\n",
    "    return lit_demo.serve()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if 'ipykernel' in sys.modules or 'ipython' in sys.modules:\n",
    "        # If running in Jupyter or IPython, avoid FLAGS parsing issues\n",
    "        try:\n",
    "            app.run(run_lit, argv=['flags_dummy', '--port=6006'])\n",
    "        except flags.Error as e:\n",
    "            print(e)\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        # Standard script execution\n",
    "        try:\n",
    "            app.run(run_lit, argv=['run_lit', '--port=6006'])\n",
    "        except flags.Error as e:\n",
    "            print(e)\n",
    "            sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc51087-6846-4394-ab7b-3266a7bfbcd9",
   "metadata": {},
   "source": [
    "# Final LIT code of Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbc4b7-9acb-48d1-a4ec-3757cab12c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (1659, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0914 01:45:30.930526 33860 752927453.py:133] Dataset: 'custom_dataset' with 1659 examples\n",
      "I0914 01:45:30.932511 33860 752927453.py:135]   truncated to 1659 examples\n",
      "I0914 01:45:30.937283 33860 dev_server.py:90] \u001b[1m\u001b[31m\n",
      " (    (           \n",
      " )\\ ) )\\ )  *   ) \n",
      "(()/((()/(` )  /( \n",
      " /(_))/(_))( )(_))\n",
      "(_)) (_)) (_(_()) \n",
      "| |  |_ _||_   _| \n",
      "| |__ | |   | |   \n",
      "|____|___|  |_|   \n",
      "\n",
      "\u001b[0m\n",
      "I0914 01:45:30.939307 33860 dev_server.py:91] \u001b[1m\u001b[32mStarting LIT server...\u001b[0m\n",
      "W0914 01:45:30.943280 33860 model.py:126] Unable to infer init spec for model 'SklearnModelWrapper'. Unsupported type '<class 'sklearn.base.ClassifierMixin'>' for parameter 'model' of '__init__'. If possible (e.g., this parameter is Optional), please implement a spec literal instead of using inferencing.\n",
      "W0914 01:45:30.947419 33860 dataset.py:154] Unable to infer init spec for dataset 'CustomDataset'. Unable to infer a type for parameter 'dataframe' of '__init__'. Please add a type hint or default value, or implement a Spec literal.\n",
      "W0914 01:45:31.124529 33860 dataset.py:154] Unable to infer init spec for dataset 'NoneDataset'. Unable to infer a type for parameter 'models' of '__init__'. Please add a type hint or default value, or implement a Spec literal.\n",
      "I0914 01:45:31.126558 33860 rouge_scorer.py:83] Using default tokenizer.\n",
      "I0914 01:45:31.135263 33860 wsgi_serving.py:46] \u001b[1m\u001b[32m\n",
      "\n",
      "Starting Server on port 6007\n",
      "You can navigate to http://127.0.0.1:6007\n",
      "\n",
      "\u001b[0m\n",
      "I0914 01:45:31.161727 33860 _internal.py:224] \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:6007\n",
      "I0914 01:45:31.168531 33860 _internal.py:224] \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "I0914 01:45:34.384078 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:34] \"GET / HTTP/1.1\" 200 -\n",
      "I0914 01:45:34.416062 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:34] \"GET /main.js HTTP/1.1\" 200 -\n",
      "I0914 01:45:34.703919 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:34] \"GET /static/favicon.png HTTP/1.1\" 200 -\n",
      "I0914 01:45:34.959354 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:34] \"POST /get_info HTTP/1.1\" 200 -\n",
      "I0914 01:45:35.094099 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:35] \"POST /get_dataset?dataset_name=custom_dataset HTTP/1.1\" 200 -\n",
      "I0914 01:45:35.105982 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:35] \"GET /static/onboarding_1_welcome.gif HTTP/1.1\" 200 -\n",
      "I0914 01:45:35.231580 33860 app.py:205] 1659 of 1659 inputs sent as IDs; reconstituting from dataset 'custom_dataset'\n",
      "I0914 01:45:35.236145 33860 caching.py:306] CachingModelWrapper 'custom_classifier': 1659 misses out of 1659 inputs\n",
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "I0914 01:45:35.422964 33860 caching.py:314] Received 1659 predictions from model\n",
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\lit_nlp\\components\\classification_results.py:83: RuntimeWarning: divide by zero encountered in log\n",
      "  pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "I0914 01:45:35.503027 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:35] \"POST /get_interpretations?model=custom_classifier&dataset_name=custom_dataset&interpreter=classification&do_predict=1 HTTP/1.1\" 200 -\n",
      "I0914 01:45:35.506665 33860 app.py:205] 1659 of 1659 inputs sent as IDs; reconstituting from dataset 'custom_dataset'\n",
      "I0914 01:45:35.510851 33860 metrics.py:56] Skipping 'probabilities': No parent provided.\n",
      "I0914 01:45:35.512854 33860 metrics.py:56] Skipping 'probabilities': No parent provided.\n",
      "I0914 01:45:35.514367 33860 metrics.py:56] Skipping 'probabilities': No parent provided.\n",
      "I0914 01:45:35.515384 33860 metrics.py:56] Skipping 'probabilities': No parent provided.\n",
      "I0914 01:45:35.516401 33860 _internal.py:224] 127.0.0.1 - - [14/Sep/2024 01:45:35] \"POST /get_metrics?model=custom_classifier&dataset_name=custom_dataset&metrics=multiclass,paired&do_predict=1 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Sequence\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from lit_nlp import dev_server\n",
    "from lit_nlp import server_flags\n",
    "from lit_nlp.api import layout\n",
    "from lit_nlp.components import minimal_targeted_counterfactuals\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "\n",
    "# Paths to your model and dataset\n",
    "MODEL_PATH = r\"C:\\Users\\nidhi\\Documents\\Spring_Semester\\Dissertation\\python files\\best_rf_model.pkl\"\n",
    "DATA_PATH = r\"C:\\Users\\nidhi\\Documents\\Spring_Semester\\Dissertation\\Kaggle-chronic kidney disease prediction\\Chronic_Kidney_Dsease_data_Cleaned.csv\"\n",
    "\n",
    "# List of 30 features used in your model\n",
    "FEATURE_COLUMNS = [\n",
    "    'SerumCreatinine', 'Itching', 'FastingBloodSugar', 'MuscleCramps',\n",
    "    'BUNLevels', 'ProteinInUrine', 'SystolicBP', 'HbA1c', 'BMI', 'FamilyHistoryKidneyDisease',\n",
    "    'Edema', 'CholesterolHDL', 'HemoglobinLevels', 'Gender', 'QualityOfLifeScore', 'CholesterolLDL', 'Statins', 'CholesterolTriglycerides',\n",
    "    'SerumElectrolytesPhosphorus', 'AntidiabeticMedications',\n",
    "    'OccupationalExposureChemicals', 'WaterQuality', 'NauseaVomiting',\n",
    "    'PhysicalActivity', 'SocioeconomicStatus', 'EducationLevel',\n",
    "    'CholesterolTotal', 'DietQuality', 'PatientID', 'GFR'\n",
    "]\n",
    "\n",
    "# Function to load your model\n",
    "def load_model(model_path):\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# Function to load your dataset\n",
    "def load_dataset(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[FEATURE_COLUMNS + ['Diagnosis']]  # Select only the 30 features plus the label column\n",
    "    print(\"Dataset loaded with shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# Wrapper for scikit-learn model to make it compatible with LIT\n",
    "class SklearnModelWrapper(lit_model.Model):\n",
    "    def __init__(self, model: ClassifierMixin):\n",
    "        self.model = model\n",
    "        self.class_names = list(model.classes_)\n",
    "\n",
    "    def predict_minibatch(self, inputs):\n",
    "        \"\"\"Predict on a batch of inputs.\"\"\"\n",
    "        input_data = np.array([[ex[col] for col in FEATURE_COLUMNS] for ex in inputs])\n",
    "        probabilities = self.model.predict_proba(input_data)\n",
    "        predicted_classes = self.model.predict(input_data)\n",
    "        return [{\n",
    "            'predictions': pred,\n",
    "            'probabilities': probs.tolist()\n",
    "        } for pred, probs in zip(predicted_classes, probabilities)]\n",
    "\n",
    "    def input_spec(self):\n",
    "        return {col: lit_types.Scalar() for col in FEATURE_COLUMNS}\n",
    "\n",
    "    def output_spec(self):\n",
    "        return {\n",
    "            'predictions': lit_types.CategoryLabel(vocab=self.class_names),\n",
    "            'probabilities': lit_types.MulticlassPreds(vocab=self.class_names),\n",
    "        }\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        return self.predict_minibatch(inputs)\n",
    "\n",
    "# Wrapper for the dataset to make it compatible with LIT\n",
    "class CustomDataset(lit_dataset.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self._examples = [{\n",
    "            **{col: row[i] for i, col in enumerate(FEATURE_COLUMNS)},\n",
    "            'label': row[-1]\n",
    "        } for _, row in dataframe.iterrows()]\n",
    "\n",
    "    def spec(self):\n",
    "        return {col: lit_types.Scalar() for col in FEATURE_COLUMNS} | {\n",
    "            'label': lit_types.CategoryLabel(),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._examples[idx]\n",
    "\n",
    "# Custom frontend layout; see api/layout.py\n",
    "modules = layout.LitModuleName\n",
    "CUSTOM_LAYOUT = layout.LitCanonicalLayout(\n",
    "    upper={\n",
    "        'Main': [\n",
    "            modules.DiveModule,\n",
    "            modules.DataTableModule,\n",
    "            modules.DatapointEditorModule,\n",
    "        ]\n",
    "    },\n",
    "    lower=layout.STANDARD_LAYOUT.lower,\n",
    "    description='Custom layout for your demo.',\n",
    ")\n",
    "CUSTOM_LAYOUTS = layout.DEFAULT_LAYOUTS | {'custom_layout': CUSTOM_LAYOUT}\n",
    "\n",
    "# Try to define the port flag, catch the DuplicateFlagError if it is already defined\n",
    "try:\n",
    "    flags.DEFINE_integer('port', 6007, 'Port to run the LIT server on.')\n",
    "except flags.DuplicateFlagError:\n",
    "    pass\n",
    "\n",
    "def run_lit(argv):\n",
    "    # Load custom model and dataset\n",
    "    model = load_model(MODEL_PATH)\n",
    "    dataframe = load_dataset(DATA_PATH)\n",
    "\n",
    "    # Wrap the model with SklearnModelWrapper\n",
    "    lit_model = SklearnModelWrapper(model)\n",
    "\n",
    "    # Wrap the dataframe with CustomDataset\n",
    "    dataset = CustomDataset(dataframe)\n",
    "\n",
    "    models = {'custom_classifier': lit_model}\n",
    "    datasets = {'custom_dataset': dataset}\n",
    "\n",
    "    # Truncate datasets if --max_examples is set.\n",
    "    max_examples = 1660  # or any other number you want to set as a limit\n",
    "    if max_examples is not None:\n",
    "        for name in datasets:\n",
    "            logging.info(\"Dataset: '%s' with %d examples\", name, len(datasets[name]))\n",
    "            datasets[name]._examples = datasets[name]._examples[:max_examples]\n",
    "            logging.info('  truncated to %d examples', len(datasets[name]))\n",
    "\n",
    "    generators = {\n",
    "        'Minimal Targeted Counterfactuals': minimal_targeted_counterfactuals.TabularMTC()\n",
    "    }\n",
    "\n",
    "    lit_demo = dev_server.Server(\n",
    "        models,\n",
    "        datasets,\n",
    "        generators=generators,\n",
    "        layouts=CUSTOM_LAYOUTS,\n",
    "        **server_flags.get_flags())\n",
    "    return lit_demo.serve()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if 'ipykernel' in sys.modules or 'ipython' in sys.modules:\n",
    "        # If running in Jupyter or IPython, avoid FLAGS parsing issues\n",
    "        try:\n",
    "            app.run(run_lit, argv=['flags_dummy', '--port=6007'])\n",
    "        except flags.Error as e:\n",
    "            print(e)\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        # Standard script execution\n",
    "        try:\n",
    "            app.run(run_lit, argv=['run_lit', '--port=6007'])\n",
    "        except flags.Error as e:\n",
    "            print(e)\n",
    "            sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c4153-3d8f-4d28-8823-e17ee651d634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
